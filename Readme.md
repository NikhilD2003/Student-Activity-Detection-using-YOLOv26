# ğŸ“ Student Activity Detection using YOLO

This repository implements a complete **computer vision pipeline** for detecting, tracking, and analyzing classroom student activities using a YOLO-based deep learning model.

The system:

â€¢ merges heterogeneous datasets  
â€¢ trains a medium-scale YOLO detector  
â€¢ evaluates performance on held-out test data  
â€¢ performs video inference with tracking and temporal smoothing  
â€¢ logs detections into CSV format  
â€¢ conducts post-hoc statistical analytics  
â€¢ provides an interactive Streamlit dashboard for visualization  

---

---

# ğŸ“ System Architecture

The pipeline consists of seven major stages:

1. Dataset Merging & Harmonization  
2. Model Training  
3. YOLO Detection Mathematics  
4. Model Evaluation  
5. Real-Time Inference + Tracking  
6. Post-Inference Analytics  
7. Interactive Streamlit Visualization  

---

---

# ğŸ“‚ Repository Structure

â”œâ”€â”€ merge_datasets.py
â”œâ”€â”€ train.py
â”œâ”€â”€ test_model.py
â”œâ”€â”€ inference.py
â”œâ”€â”€ analyze.py
â”œâ”€â”€ streamlit_app.py
â”œâ”€â”€ inference_engine.py
â”œâ”€â”€ analytics.py
â”œâ”€â”€ datasets/
â”‚ â””â”€â”€ merged_dataset/
â”‚ â”œâ”€â”€ train/
â”‚ â”‚ â”œâ”€â”€ images/
â”‚ â”‚ â””â”€â”€ labels/
â”‚ â”œâ”€â”€ val/
â”‚ â”‚ â”œâ”€â”€ images/
â”‚ â”‚ â””â”€â”€ labels/
â”‚ â”œâ”€â”€ test/
â”‚ â”‚ â”œâ”€â”€ images/
â”‚ â”‚ â””â”€â”€ labels/
â”‚ â”‚ â””â”€â”€ dataset.yaml
â”œâ”€â”€ weights/
â”‚ â””â”€â”€ best.pt
â”œâ”€â”€ outputs/
â”‚ â”œâ”€â”€ output_inference.mp4
â”‚ â””â”€â”€ detections_log.csv
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ packages.txt
â””â”€â”€ README.md

yaml
Copy code

---

---

# 1ï¸âƒ£ Dataset Merging & Preparation

### Script: `merge_datasets.py`

### ğŸ¯ Objective

Combine Dataset-A and Dataset-B into a **single unified dataset** while:

â€¢ resolving overlapping class names  
â€¢ re-indexing class IDs  
â€¢ balancing splits  
â€¢ creating Train / Validation / Test folders  
â€¢ generating a unified YAML configuration file  

---

## ğŸ“Š Split Ratios

| Split | Ratio |
|------|------|
| Train | 70% |
| Validation | 15% |
| Test | 15% |

---

---

# 2ï¸âƒ£ Model Training

### Script: `train.py`

### Base Model

Pretrained YOLO checkpoint used for transfer learning.

---

## âš™ï¸ Hyperparameters

| Parameter | Value |
|---------|------|
| epochs | 15 |
| batch_size | 12 |
| workers | 8 |
| patience | 15 |
| image size | 640 Ã— 640 |

---

---

# ğŸ§  CNN Feature Extraction

All training images are resized to **640 Ã— 640**.

The YOLO backbone CNN progressively downsamples spatial resolution and extracts multi-scale features for detection.

These features encode:

â€¢ head pose  
â€¢ posture  
â€¢ hand activity  
â€¢ gaze direction  
â€¢ body alignment  

---

---

# ğŸ”„ Gradient Descent Optimization

During training, weights are updated using back-propagation with gradient descent to minimize the total YOLO loss:

\[
L = \lambda_{box} L_{box} + \lambda_{obj} L_{obj} + \lambda_{cls} L_{cls}
\]

---

---

# ğŸ“ YOLO Bounding Box Prediction Mathematics

Predicted parameters:

(tx, ty, tw, th)

Converted to image-space coordinates:

\[
b_x = \sigma(t_x) + c_x
\]

\[
b_y = \sigma(t_y) + c_y
\]

\[
b_w = p_w \cdot e^{t_w}
\]

\[
b_h = p_h \cdot e^{t_h}
\]

Final confidence:

\[
Score = P(object) \times P(class)
\]

---

---

# 3ï¸âƒ£ Model Evaluation

### Script: `test_model.py`

Metrics computed:

â€¢ Precision  
â€¢ Recall  
â€¢ mAP@50  
â€¢ mAP@50â€“95  
â€¢ Confusion Matrix  

---

---

# 4ï¸âƒ£ Real-Time Inference & Tracking

### Script: `inference.py`

---

## ğŸ¯ Detection Thresholds

| Parameter | Value |
|--------|------|
| Confidence Threshold | 0.18 |
| IoU Threshold | 0.35 |

---

## ğŸ§­ Multi-Object Tracking

Tracking is performed using ByteTrack or BoT-SORT to provide:

â€¢ persistent student identities  
â€¢ occlusion handling  
â€¢ appearance-based matching  

---

## ğŸ Temporal Smoothing

Predictions are stabilized using a sliding temporal window of nine frames.

Final activity label is chosen by majority vote.

---

---

# 5ï¸âƒ£ Post-Inference Analytics

Statistical measures include:

â€¢ mean confidence per class  
â€¢ class frequency  
â€¢ per-student activity duration  
â€¢ detection reliability  
â€¢ imbalance diagnostics  

---

---

# ğŸ“Š Analysis Results (Typical)

After fine-tuning:

| Metric | Value |
|------|------|
| Precision | ~0.95 |
| Recall | ~0.94 |
| mAP@50 | ~0.97 |
| mAP@50â€“95 | ~0.74 |

Tracking behavior after tuning:

â€¢ stable IDs for seated students  
â€¢ limited fragmentation  
â€¢ rare merges  

---

---

# 6ï¸âƒ£ Interactive Streamlit Dashboard

<img width="1864" height="886" alt="image" src="https://github.com/user-attachments/assets/ec94dceb-4091-4077-b454-10503691ed02" />

Launch locally:

```bash
streamlit run streamlit_app.py

Dashboard features:

â€¢ upload classroom video
â€¢ live inference preview
â€¢ progress indicator
â€¢ activity distribution plots
â€¢ temporal timelines
â€¢ CSV/video downloads
â€¢ per-student analytics
