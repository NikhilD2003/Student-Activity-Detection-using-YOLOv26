# ğŸ“ Student Activity Detection using YOLO

This repository implements a complete **computer vision pipeline** for detecting, tracking, and analyzing classroom student activities using a YOLO-based deep learning model.

The system:

â€¢ merges heterogeneous datasets  
â€¢ trains a medium-scale YOLO detector  
â€¢ evaluates performance on held-out test data  
â€¢ performs video inference with tracking and temporal smoothing  
â€¢ logs detections into CSV format  
â€¢ conducts post-hoc statistical analytics  

---

---

# ğŸ“ System Architecture

The pipeline consists of six major stages:

1. Dataset Merging & Harmonization  
2. Model Training  
3. YOLO Detection Mathematics  
4. Model Evaluation  
5. Real-Time Inference + Tracking  
6. Post-Inference Analytics  

---

---

# ğŸ“‚ Repository Structure

â”œâ”€â”€ merge_datasets.py
â”œâ”€â”€ train.py
â”œâ”€â”€ test_model.py
â”œâ”€â”€ inference.py
â”œâ”€â”€ analyze.py
â”œâ”€â”€ datasets/
â”‚ â””â”€â”€ merged_dataset/
â”‚ â”œâ”€â”€ train/
â”‚ â”‚ â”œâ”€â”€ images/
â”‚ â”‚ â””â”€â”€ labels/
â”‚ â”œâ”€â”€ val/
â”‚ â”‚ â”œâ”€â”€ images/
â”‚ â”‚ â””â”€â”€ labels/
â”‚ â”œâ”€â”€ test/
â”‚ â”‚ â”œâ”€â”€ images/
â”‚ â”‚ â””â”€â”€ labels/
â”‚ â””â”€â”€ dataset.yaml
â”œâ”€â”€ weights/
â”‚ â””â”€â”€ best.pt
â”œâ”€â”€ outputs/
â”‚ â”œâ”€â”€ output_inference.mp4
â”‚ â””â”€â”€ detections_log.csv
â””â”€â”€ README.md

---

---

# 1ï¸âƒ£ Dataset Merging & Preparation

### Script: `merge_datasets.py`

### ğŸ¯ Objective

Combine Dataset-A and Dataset-B into a **single unified dataset** while:

â€¢ resolving overlapping class names  
â€¢ re-indexing class IDs  
â€¢ balancing splits  
â€¢ creating Train / Validation / Test folders  
â€¢ generating a unified YAML configuration file  

---

## ğŸ“Š Split Ratios

| Split | Ratio |
|------|------|
| Train | 70% |
| Validation | 15% |
| Test | 15% |

---

## ğŸ“‚ Output Folder Layout

merged_dataset/
â”œâ”€â”€ train/images
â”œâ”€â”€ train/labels
â”œâ”€â”€ val/images
â”œâ”€â”€ val/labels
â”œâ”€â”€ test/images
â”œâ”€â”€ test/labels
â””â”€â”€ dataset.yaml

### `dataset.yaml` Contains:

â€¢ relative paths to train/val/test  
â€¢ number of classes  
â€¢ ordered activity names  

---

---

# 2ï¸âƒ£ Model Training

### Script: `train.py`

### Base Model

---

## âš™ï¸ Hyperparameters

| Parameter | Value |
|---------|------|
| epochs | 15 |
| batch_size | 12 |
| workers | 8 |
| patience | 15 |
| image size | 640 Ã— 640 |

---

---

# ğŸ§  CNN Feature Extraction

All training images are resized to **640 Ã— 640**.

The YOLO backbone CNN progressively downsamples:

640 Ã— 640 â†’ 20 Ã— 20 feature grid


Each grid cell captures:

â€¢ facial orientation  
â€¢ head pose  
â€¢ hand movement  
â€¢ posture  
â€¢ body alignment  

These features are forwarded to the detection head for anchor-based regression.

---

---

# ğŸ”„ Gradient Descent Optimization

During training, weights are updated using **back-propagation with gradient descent** to minimize the total YOLO loss:

\[
L = \lambda_{box} L_{box} + \lambda_{obj} L_{obj} + \lambda_{cls} L_{cls}
\]

Where:

â€¢ `L_box` â†’ bounding box regression loss  
â€¢ `L_obj` â†’ objectness confidence loss  
â€¢ `L_cls` â†’ classification loss  

---

---

# ğŸ“ YOLO Bounding Box Prediction Mathematics

For each anchor box, the network predicts:

(tx, ty, tw, th)


These are converted to image-space coordinates as:

### Center Coordinates

\[
b_x = \sigma(t_x) + c_x
\]

\[
b_y = \sigma(t_y) + c_y
\]

Where:

â€¢ `(c_x, c_y)` are grid-cell offsets  
â€¢ `Ïƒ` is the sigmoid function  

---

### Width & Height

\[
b_w = p_w \cdot e^{t_w}
\]

\[
b_h = p_h \cdot e^{t_h}
\]

Where:

â€¢ `(p_w, p_h)` are anchor dimensions  

---

### Final Confidence

\[
Score = P(object) \times P(class)
\]

---

---

# 3ï¸âƒ£ Model Evaluation

### Script: `test_model.py`

### Configuration

split = test
workers = 8


---

## ğŸ“Š Metrics Computed

â€¢ Precision per activity  
â€¢ Recall  
â€¢ mAP@50  
â€¢ mAP@50-95  
â€¢ Confusion matrix  

---

---

# 4ï¸âƒ£ Real-Time Inference & Tracking

### Script: `inference.py`

---

## ğŸ¯ Detection Thresholds

| Parameter | Value |
|--------|------|
| Confidence Threshold | 0.18 |
| IoU Threshold | 0.35 |

---

---

# ğŸ§­ Multi-Object Tracking

Tracker configuration:

bytetrack.yaml


Responsibilities:

â€¢ assigns persistent student IDs  
â€¢ handles occlusion  
â€¢ supports re-identification  

---

---

# ğŸ Temporal Smoothing

Predictions are stabilized using:

Window = 9 frames


Final class label = **majority vote** across window.

---

---

# ğŸ” Re-Identification Logic

If a newly detected student appears within **90 pixels** of a previous track center:

â¡ the original ID is reused.

---

---

# ğŸ“¤ Inference Outputs

---

## ğŸ¥ Annotated Video

outputs/output_inference.mp4


Displays:

â€¢ bounding boxes  
â€¢ student IDs  
â€¢ activity labels  
â€¢ confidence scores  

---

---

## ğŸ“„ Detection Log

outputs/detections_log.csv


Columns:

timestamp,
confidence,
student_id,
x1, y1, x2, y2,
activity


---

---

# 5ï¸âƒ£ Post-Inference Analytics

### Script: `analyze.py`

---

## ğŸ“Š Statistical Analysis Performed

â€¢ mean confidence per class  
â€¢ standard deviation  
â€¢ frequency distribution  
â€¢ activity duration per student  
â€¢ detection reliability  
â€¢ class imbalance diagnostics  

---

---

# ğŸ” End-to-End Pipeline Summary

Dataset A + Dataset B
â†“
merge_datasets.py
â†“
Merged Dataset + YAML
â†“
train.py
â†“
best.pt
â†“ â†“
test_model.py inference.py
â†“
output_inference.mp4 + detections_log.csv
â†“
analyze.py


---

---

# ğŸš€ Applications

â€¢ classroom engagement monitoring  
â€¢ smart classroom analytics  
â€¢ academic research  
â€¢ behavioral modeling  
â€¢ automated attendance systems  

---

---
# ğŸ‘¤ Author

Nikhilesh Dubey


